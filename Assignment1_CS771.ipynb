{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pDxgl5TdxGijKxOx2HgGwkhBLJYNmFI9",
      "authorship_tag": "ABX9TyN/0IPeERwLvd/3llrnWYuV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshal1074/Bussiness-Analytics/blob/main/Assignment1_CS771.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qv82AQIMupC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b4befa-aaed-4145-cf32-75e90ea3152e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 49.84399362072206\n",
            "Training Time: 1.5411152839660645 seconds\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# You are not allowed to use any ML libraries e.g. sklearn, scipy, keras, tensorflow etc\n",
        "\n",
        "# SUBMIT YOUR CODE AS A SINGLE PYTHON (.PY) FILE INSIDE A ZIP ARCHIVE\n",
        "# THE NAME OF THE PYTHON FILE MUST BE submit.py\n",
        "# DO NOT INCLUDE OTHER PACKAGES LIKE SKLEARN, SCIPY, KERAS,TENSORFLOW ETC IN YOUR CODE\n",
        "# THE USE OF ANY MACHINE LEARNING LIBRARIES WILL RESULT IN A STRAIGHT ZERO\n",
        "\n",
        "# DO NOT CHANGE THE NAME OF THE METHOD my_fit BELOW\n",
        "# THESE WILL BE INVOKED BY THE EVALUATION SCRIPT. CHANGING THESE NAMES WILL CAUSE EVALUATION FAILURE\n",
        "\n",
        "# You may define any new functions, variables, classes here\n",
        "# For example, functions to calculate next coordinate or step length\n",
        "# def  ST(x,lamda):\n",
        "#     return np.sign(x)*np.maximum(np.abs(x)-lamda,0)\n",
        "\n",
        "\n",
        "def HT(v, k):\n",
        "    t = np.zeros_like(v)\n",
        "    if k < 1:\n",
        "        return t\n",
        "    else:\n",
        "        ind = np.argsort(abs(v))[-k:]\n",
        "        t[ind] = v[ind]\n",
        "        return t\n",
        "\n",
        "\n",
        "def predict(X_trn, model):\n",
        "    return X_trn.dot(model)\n",
        "\n",
        "\n",
        "def calculate_mae(X_trn, y_trn, model):\n",
        "    predictions = predict(X_trn, model)\n",
        "    mae = np.mean(np.abs(predictions - y_trn))\n",
        "    return mae\n",
        "\n",
        "\n",
        "################################\n",
        "# Non Editable Region Starting #\n",
        "################################\n",
        "def my_fit(X_trn, y_trn):\n",
        "    ################################\n",
        "    #  Non Editable Region Ending  #\n",
        "    ################################\n",
        "    # #  updating w using coordinate descent\n",
        "    # N,D=X_trn.shape  # N=no.of data samples ,D=no.of features\n",
        "    # model= np.zeros(D) # initialise w to zero\n",
        "    # w_prev=model.copy()  # soring the prev values of w\n",
        "    # lamda=1\n",
        "    # tolerance=1e-4\n",
        "    # maxiter=100\n",
        "    iter = 0\n",
        "    # while(iter<maxiter):\n",
        "    #     for j in range(D):\n",
        "    #         r=y_trn-np.dot(X_trn,model) # residual\n",
        "    #         # gradient of loss function ,which gives the form a*w-c\n",
        "    #         # gradient of L1 norm is lamda*sign(w)\n",
        "    #         # for optimimum of w , w= c+laamda*sign(w)/a\n",
        "    #         a= np.dot(X_trn[:, j],X_trn[:, j]) # sum of all x*2\n",
        "    #         c=r+model[j]*X_trn[:,j]  # resudal without w_j\n",
        "    #         model[j]=ST(np.dot(X_trn[:,j],c),N*lamda)/a   #updating each wj\n",
        "    #         if (np.allclose(w_prev, model, atol=tolerance)):\n",
        "    #             break     #break condition\n",
        "\n",
        "    #     w_prev=model.copy()\n",
        "    #     iter=iter+1\n",
        "    # Projection gradient method\n",
        "\n",
        "    N, D = X_trn.shape  # N=no.of data samples ,D=no.of features\n",
        "    model = np.zeros(D)  # initialise w to zero\n",
        "    neta = 1e-3  # learning rate (reduced further)\n",
        "    # lamda=1 #thresold\n",
        "    tolerance = 1e-4\n",
        "    maxiter = 1000\n",
        "    S = 512\n",
        "    while (iter < maxiter):\n",
        "        # calculate gradient of loss function\n",
        "        gradient = (1 / N) * (X_trn.T.dot(X_trn.dot(model) - y_trn))\n",
        "        model_new = model - neta * gradient\n",
        "        # # apply soft thresholding\n",
        "        # model=ST(model_new,lamda)\n",
        "        # apply hard thresholding\n",
        "        # Apply hard thresholding to keep the iterates sparse\n",
        "        model = HT(model_new, S)\n",
        "        # apply convergence\n",
        "        if np.linalg.norm(model - model_new) < tolerance:\n",
        "            break\n",
        "        model = model_new\n",
        "        iter = iter + 1\n",
        "\n",
        "    # Use this method to train your model using training CRPs\n",
        "    # Your method should return a 2048-dimensional vector that is 512-sparse\n",
        "    # No bias term allowed -- return just a single 2048-dim vector as output\n",
        "    # If the vector you return is not 512-sparse, it will be sparsified using hard-thresholding\n",
        "    return model  # Return the trained model\n",
        "\n",
        "\n",
        "X = np.loadtxt('/train_challenges.dat')\n",
        "Y = np.loadtxt('/train_responses.dat')\n",
        "w = my_fit(X, Y)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "mae = calculate_mae(X, Y, w)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "w = my_fit(X, Y)\n",
        "end_time = time.time()\n",
        "train_time = end_time - start_time\n",
        "\n",
        "print(\"Training Time:\", train_time, \"seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHzubyopvGgA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AM7zIAXfvK4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}